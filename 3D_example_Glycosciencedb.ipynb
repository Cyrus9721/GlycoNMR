{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ffb8a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from run_no_val import run\n",
    "\n",
    "from model_3d.Spherenet_NMR import SphereNet\n",
    "\n",
    "from load_Glycosciencedb_3d import create_graph_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194709f3",
   "metadata": {},
   "source": [
    "##### 1, Load the Glycoscience dataset for 3D GNN models\n",
    "\n",
    "This code is modified from the 2D loading method.\n",
    "\n",
    "We first randomly split the glycans into training set and test set. \n",
    "\n",
    "Due to the overfitting and the size of the dataset, we do not include a validation set here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ab7bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "501dc34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------loading NMR Graph List-------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 299/299 [00:06<00:00, 45.54it/s]\n"
     ]
    }
   ],
   "source": [
    "Create = create_graph_experiment()\n",
    "\n",
    "train_data_exp, test_data_exp = Create.create_all_graph_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2a27c9",
   "metadata": {},
   "source": [
    "##### 2, Initialize the node embedding size\n",
    "\n",
    "The number of number of the embedding size, is the input to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aefb8068",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embedding_size = train_data_exp[0].z.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbea5dd5",
   "metadata": {},
   "source": [
    "##### 3, Initialize and train the SphereNet,\n",
    "\n",
    "Our implementation is modified from https://github.com/divelab/DIG/tree/dig-stable. \n",
    "\n",
    "To apply SphereNet to our tasks, we replaced the global pooling layer, which is needed for predicting the properties of whole molecules, and added a layer that maps the learned embedding of each atom to its NMR chemical shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40e27333",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SphereNet(energy_and_force=False, in_embed_size = node_embedding_size, cutoff=5.0, num_layers=2,\n",
    "                  hidden_channels=128, out_channels=1, int_emb_size=64,\n",
    "                  basis_emb_size_dist=8, basis_emb_size_angle=8, basis_emb_size_torsion=8, out_emb_channels=128,\n",
    "                  num_spherical=3, num_radial=6, envelope_exponent=5,\n",
    "                  num_before_skip=1, num_after_skip=2, num_output_layers=1)\n",
    "loss_func = torch.nn.L1Loss()\n",
    "run3d = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5bfe00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Params: 552934\n",
      "\n",
      "=====Epoch 1\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 120/120 [00:02<00:00, 40.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 30/30 [00:00<00:00, 73.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'Train': 8.396147856613, 'Test': 0.9185028}\n",
      "\n",
      "=====Epoch 2\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████| 120/120 [00:02<00:00, 49.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 30/30 [00:00<00:00, 73.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'Train': 0.576868024840951, 'Test': 0.6139659}\n",
      "\n",
      "=====Epoch 3\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|█████████████████████████████████████████| 120/120 [00:02<00:00, 50.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|███████████████████████████████████████████| 30/30 [00:00<00:00, 74.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'Train': 0.37055806890130044, 'Test': 0.3965973}\n",
      "\n",
      "=====Epoch 4\n",
      "\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 83%|██████████████████████████████████▏      | 100/120 [00:02<00:00, 51.09it/s]"
     ]
    }
   ],
   "source": [
    "train_loss_list, test_rmse_list = run3d.run(device=device, train_dataset = train_data_exp, test_dataset = test_data_exp ,\n",
    "                                            model = model, loss_func=loss_func,\n",
    "                                            epochs=5, batch_size=2, vt_batch_size= 2, lr=0.001, lr_decay_factor=0.5, lr_decay_step_size=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb37d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bf33fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38d7a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:3dgnn]",
   "language": "python",
   "name": "conda-env-3dgnn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
